{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data - Final Work - Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configuration for Spark + JVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.master = \"local[*]\"\n",
    "launcher.driver_memory = '20g'\n",
    "launcher.executor_memory = '20g'\n",
    "launcher.verbose = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.conf.set(\"spark.app.name\", \"scalaXgbTest\")\n",
    "launcher.num_executors = 3\n",
    "launcher.executor_cores = 7 //launcher.conf.spark.executor.cores = 8\n",
    "launcher.conf.spark.task.cpus = 6\n",
    "launcher.driver_memory = '4g'\n",
    "launcher.executor_memory = '4g'\n",
    "launcher.conf.set(\"spark.executor.heartbeatInterval\", \"6000s\")\n",
    "launcher.conf.set(\"spark.yarn.scheduler.heartbeat.interval-ms\", \"10000s\")\n",
    "launcher.conf.set(\"spark.network.timeout\", \"10000s\")\n",
    "launcher.conf.set(\"spark.yarn.executor.memoryOverhead\", \"8192\")\n",
    "launcher.conf.set(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "launcher.jars = [\"file://some/jar.jar\", \"xgboost-maven-0.82/xgboost4j-spark-0.82.jar\", \"xgboost-maven-0.82/xgboost4j-0.82.jar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spylon-kernel\n",
      "local[*]\n"
     ]
    }
   ],
   "source": [
    "println(sc.appName)\n",
    "println(sc.master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n",
       "import org.apache.spark.sql.expressions._\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._      // include the Spark Types to define our schema\n",
    "import org.apache.spark.sql.functions._  // include the Spark helper functions\n",
    "import spark.implicits._                 // For implicit conversions like converting RDDs to DataFrames\n",
    "import org.apache.spark.sql.expressions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_schema: org.apache.spark.sql.types.MapType = MapType(StringType,StructType(StructField(accuracy,DoubleType,true), StructField(address,StringType,true), StructField(altitude,DoubleType,true), StructField(country,StringType,true), StructField(latitude,DoubleType,true), StructField(longitude,DoubleType,true), StructField(provider,StringType,true), StructField(timestamp,StructType(StructField(date,LongType,true), StructField(day,LongType,true), StructField(hours,LongType,true), StructField(month,LongType,true), StructField(nanos,LongType,true), StructField(seconds,LongType,true), StructField(time,LongType,true), StructField(timezoneOffset,LongType,true), StructField(year,LongType,true)),true), StructField(uid,StringType,true)),true)\n",
       "schema: org.apache.spark.sql.types.StructType = S...\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val location_schema =\n",
    "    MapType(StringType,\n",
    "        new StructType()\n",
    "            .add(\"accuracy\", DoubleType)\n",
    "            .add(\"address\", StringType)\n",
    "            .add(\"altitude\", DoubleType)\n",
    "            .add(\"country\", StringType)\n",
    "            .add(\"latitude\", DoubleType)\n",
    "            .add(\"longitude\", DoubleType)\n",
    "            .add(\"provider\", StringType)\n",
    "            .add(\"timestamp\", \n",
    "             new StructType()\n",
    "                .add(\"date\", LongType)\n",
    "                .add(\"day\", LongType)\n",
    "                .add(\"hours\", LongType)\n",
    "                .add(\"month\", LongType)\n",
    "                .add(\"nanos\", LongType)\n",
    "                .add(\"seconds\", LongType)\n",
    "                .add(\"time\", LongType)\n",
    "                .add(\"timezoneOffset\", LongType)\n",
    "                .add(\"year\", LongType)\n",
    "            )\n",
    "            .add(\"uid\", StringType)\n",
    "        )\n",
    "\n",
    "val schema = new StructType()\n",
    "    .add(\"locations\", location_schema)\n",
    "    .add(\"user-locations\",\n",
    "        MapType(StringType, location_schema)\n",
    "    )\n",
    "    .add(\"users\",\n",
    "        MapType(StringType,\n",
    "            new StructType()\n",
    "                .add(\"email\", StringType)\n",
    "                .add(\"username\", StringType)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import JSON DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [locations: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>, user-locations: map<string,map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>> ... 1 more field]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"multiline\", true).schema(schema).json(\"trackme-sample-data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locations: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- accuracy: double (nullable = true)\n",
      " |    |    |-- address: string (nullable = true)\n",
      " |    |    |-- altitude: double (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- latitude: double (nullable = true)\n",
      " |    |    |-- longitude: double (nullable = true)\n",
      " |    |    |-- provider: string (nullable = true)\n",
      " |    |    |-- timestamp: struct (nullable = true)\n",
      " |    |    |    |-- date: long (nullable = true)\n",
      " |    |    |    |-- day: long (nullable = true)\n",
      " |    |    |    |-- hours: long (nullable = true)\n",
      " |    |    |    |-- month: long (nullable = true)\n",
      " |    |    |    |-- nanos: long (nullable = true)\n",
      " |    |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |    |-- time: long (nullable = true)\n",
      " |    |    |    |-- timezoneOffset: long (nullable = true)\n",
      " |    |    |    |-- year: long (nullable = true)\n",
      " |    |    |-- uid: string (nullable = true)\n",
      " |-- user-locations: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: map (valueContainsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |    |-- accuracy: double (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |    |-- altitude: double (nullable = true)\n",
      " |    |    |    |-- country: string (nullable = true)\n",
      " |    |    |    |-- latitude: double (nullable = true)\n",
      " |    |    |    |-- longitude: double (nullable = true)\n",
      " |    |    |    |-- provider: string (nullable = true)\n",
      " |    |    |    |-- timestamp: struct (nullable = true)\n",
      " |    |    |    |    |-- date: long (nullable = true)\n",
      " |    |    |    |    |-- day: long (nullable = true)\n",
      " |    |    |    |    |-- hours: long (nullable = true)\n",
      " |    |    |    |    |-- month: long (nullable = true)\n",
      " |    |    |    |    |-- nanos: long (nullable = true)\n",
      " |    |    |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |    |    |-- time: long (nullable = true)\n",
      " |    |    |    |    |-- timezoneOffset: long (nullable = true)\n",
      " |    |    |    |    |-- year: long (nullable = true)\n",
      " |    |    |    |-- uid: string (nullable = true)\n",
      " |-- users: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- email: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown raw DB into contextual structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "locationsDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, value: struct<accuracy: double, address: string ... 7 more fields>]\n",
       "userLocationsDF: org.apache.spark.sql.DataFrame = [uid: string, timestamp: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>]\n",
       "usersDF: org.apache.spark.sql.DataFrame = [uid: string, user_attr: struct<email: string, username: string>]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val locationsDF = df.select(explode($\"locations\") as Seq(\"timestamp_id\", \"value\"))\n",
    "val userLocationsDF = df.select(explode($\"user-locations\") as Seq(\"uid\", \"timestamp\"))\n",
    "val usersDF = df.select(explode($\"users\") as Seq(\"uid\", \"user_attr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = false)\n",
      " |-- user_attr: struct (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to flatten schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Column\n",
       "flattenSchema: (schema: org.apache.spark.sql.types.StructType, prefix: String)Array[org.apache.spark.sql.Column]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Column\n",
    "\n",
    "def flattenSchema(schema: StructType, prefix: String = null) : Array[Column] = {\n",
    "  schema.fields.flatMap(f => {\n",
    "    val colName = if (prefix == null) f.name else (prefix + \".\" + f.name)\n",
    "\n",
    "    f.dataType match {\n",
    "      case st: StructType => flattenSchema(st, colName)\n",
    "      case _ => Array(col(colName))\n",
    "    }\n",
    "  })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat struct DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatLocationsDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 16 more fields]\n",
       "flatUserLocationsDF: org.apache.spark.sql.DataFrame = [uid: string, timestamp: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>]\n",
       "flatUsersDF: org.apache.spark.sql.DataFrame = [uid: string, email: string ... 1 more field]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flatLocationsDF = locationsDF.select(flattenSchema(locationsDF.schema):_*)\n",
    "val flatUserLocationsDF = userLocationsDF.select(flattenSchema(userLocationsDF.schema):_*)\n",
    "val flatUsersDF = usersDF.select(flattenSchema(usersDF.schema):_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp_id: string (nullable = false)\n",
      " |-- accuracy: double (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- altitude: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- hours: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- nanos: long (nullable = true)\n",
      " |-- seconds: long (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- timezoneOffset: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1602119776824,15.666000366210938,R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil,14.90000057220459,Brazil,-22.9556468,-43.1880249,fused,7,3,22,9,824000000,16,1602119776824,180,120,H5LG3vN3jcPlcbJ2A5RGo6H4AHw2]\n",
      "[1602119934507,15.967000007629395,R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil,15.300000190734863,Brazil,-22.9556367,-43.1880211,fused,7,3,22,9,507000000,54,1602119934507,180,120,H5LG3vN3jcPlcbJ2A5RGo6H4AHw2]\n"
     ]
    }
   ],
   "source": [
    "flatLocationsDF.take(2).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5Jf44SGWhzZmxsZs7n6KLzrHark1,rodrigomesquita0@gmail.com,rodrigomesquita0]\n",
      "[BHNpkg1LH2Sna0axjb8pFWDIycD2,vivian.lopesg@gmail.com,vivian.lopesg]\n"
     ]
    }
   ],
   "source": [
    "flatUsersDF.take(2).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for distance calculation based on lat/long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element version - calculate_distance_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.math._\n",
       "calculate_distance_elem: (lat1: Double, lon1: Double, lat2: Double, lon2: Double)Double\n",
       "calculate_distance_elem_sqlfunc: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4815/1659349508@6e7871ea,DoubleType,List(Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double])),None,false,true)\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.math._\n",
    "\n",
    "def calculate_distance_elem(lat1:Double, lon1:Double, lat2:Double, lon2:Double):Double = {   \n",
    "    val earth_radius = 6371e3;           // meters\n",
    "    val phi1 = lat1 * Pi/180;                  // radians\n",
    "    val phi2 = lat2 * Pi/180;                  // radians\n",
    "    val delta_phi = phi2 - phi1;               // radians\n",
    "\n",
    "    val delta_lampda = (lon2 - lon1) * Pi/180; // radians\n",
    "\n",
    "    val a = sin(delta_phi/2)*sin(delta_phi/2) + cos(phi1)*cos(phi2)*sin(delta_lampda/2)*sin(delta_lampda/2);\n",
    "    val c = 2*atan2(sqrt(a), sqrt(1-a));\n",
    "\n",
    "    val d = earth_radius*c; // meters\n",
    "    \n",
    "    return d\n",
    "}\n",
    "\n",
    "val calculate_distance_elem_sqlfunc = udf(calculate_distance_elem(_,_,_,_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - calculate_distance_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "43: error: not found: value calculate_distance_elem",
     "output_type": "error",
     "traceback": [
      "<console>:43: error: not found: value calculate_distance_elem",
      "       val dist = calculate_distance_elem(lat1, lon1, lat2, lon2)",
      "                  ^",
      ""
     ]
    }
   ],
   "source": [
    "val lat1 = -22.9556473\n",
    "val lon1 = -43.1881019\n",
    "\n",
    "val lat2 = -23.9556473\n",
    "val lon2 = -44.1881019\n",
    "\n",
    "val dist = calculate_distance_elem(lat1, lon1, lat2, lon2)\n",
    "\n",
    "assert (dist == 150894.75616346067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.math.Pi\n",
       "import org.apache.spark.sql.functions._\n",
       "calculate_distance_col: (lat1: org.apache.spark.sql.Column, lon1: org.apache.spark.sql.Column, lat2: org.apache.spark.sql.Column, lon2: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.math.Pi\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "def calculate_distance_col(lat1:org.apache.spark.sql.Column, lon1:org.apache.spark.sql.Column, lat2:org.apache.spark.sql.Column, lon2:org.apache.spark.sql.Column):org.apache.spark.sql.Column = {   \n",
    "    val earth_radius = 6371e3;           // meters\n",
    "    val pi_over_180 = lit(Pi/180);\n",
    "    val phi1 = lat1 * pi_over_180;                  // radians\n",
    "    val phi2 = lat2 * pi_over_180;                  // radians\n",
    "    val delta_phi = phi2 - phi1;               // radians\n",
    "\n",
    "    val delta_lampda = (lon2 - lon1) * pi_over_180; // radians\n",
    "\n",
    "    val a = sin(delta_phi/2)*sin(delta_phi/2) + cos(phi1)*cos(phi2)*sin(delta_lampda/2)*sin(delta_lampda/2);\n",
    "    val c = lit(2)*atan2(sqrt(a), sqrt(lit(1)-a));\n",
    "\n",
    "    val d = lit(earth_radius)*c; // meters\n",
    "    \n",
    "    return d;\n",
    "}\n",
    "\n",
    "// val calculate_distance_sqlfunc = udf(calculate_distance(_,_,_,_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat_col: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@93651ba\n",
       "lon_col: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@74119f1f\n",
       "lat2: org.apache.spark.sql.Column = latitude\n",
       "lat1: org.apache.spark.sql.Column = lag(latitude, 1, NULL) OVER (ORDER BY timestamp_id ASC NULLS FIRST unspecifiedframe$())\n",
       "lon2: org.apache.spark.sql.Column = longitude\n",
       "lon1: org.apache.spark.sql.Column = lag(longitude, 1, NULL) OVER (ORDER BY timestamp_id ASC NULLS FIRST unspecifiedframe$())\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val lat_col = Window.partitionBy(\"latitude\").orderBy($\"timestamp_id\".asc)\n",
    "// val lon_col = Window.partitionBy(\"longitude\").orderBy($\"timestamp_id\".asc)\n",
    "val lat_col = Window.orderBy($\"timestamp_id\".asc)\n",
    "val lon_col = Window.orderBy($\"timestamp_id\".asc)\n",
    "\n",
    "val lat2 = col(\"latitude\")\n",
    "val lat1 = lag(\"latitude\", 1).over(lat_col)\n",
    "// val lat1 = when((lag(\"latitude\", 1).over(lat_col)).isNotNull, lag(\"latitude\", 1).over(lat_col)).otherwise(0)\n",
    "\n",
    "val lon2 = col(\"longitude\")\n",
    "val lon1 = lag(\"longitude\", 1).over(lat_col)\n",
    "// val lon1 = when((lag(\"longitude\", 1).over(lon_col)).isNotNull, lag(\"longitude\", 1).over(lon_col)).otherwise(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+-------------------------+---------------+\n",
      "|timestamp_id |accuracy          |address                                                                   |altitude          |country|latitude   |longitude  |provider|date|day|hours|month|nanos    |seconds|time         |timezoneOffset|year|uid                         |email                    |username       |\n",
      "+-------------+------------------+--------------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+-------------------------+---------------+\n",
      "|1602124371945|14.199000358581543|R. Tôrres Homem, 538 - Vila Isabel, Rio de Janeiro - RJ, 20551-070, Brasil|19.200000762939453|Brasil |-22.9143424|-43.2479267|fused   |7   |3  |23   |9    |945000000|51     |1602124371945|180           |120 |PgXtDvjeJQgc6FzN98KueShvEMa2|viniciusmgaspar@gmail.com|viniciusmgaspar|\n",
      "|1602124491961|13.723999977111816|R. Tôrres Homem, 538 - Vila Isabel, Rio de Janeiro - RJ, 20551-070, Brasil|17.0              |Brasil |-22.9143476|-43.2479225|fused   |7   |3  |23   |9    |961000000|51     |1602124491961|180           |120 |PgXtDvjeJQgc6FzN98KueShvEMa2|viniciusmgaspar@gmail.com|viniciusmgaspar|\n",
      "|1602124616689|14.432000160217285|R. Tôrres Homem, 545 - Vila Isabel, Rio de Janeiro - RJ, 20551-070, Brasil|19.200000762939453|Brasil |-22.9143736|-43.2479302|fused   |7   |3  |23   |9    |689000000|56     |1602124616689|180           |120 |PgXtDvjeJQgc6FzN98KueShvEMa2|viniciusmgaspar@gmail.com|viniciusmgaspar|\n",
      "|1602124677042|14.432000160217285|R. Tôrres Homem, 545 - Vila Isabel, Rio de Janeiro - RJ, 20551-070, Brasil|19.200000762939453|Brasil |-22.9143736|-43.2479302|fused   |7   |3  |23   |9    |42000000 |57     |1602124677042|180           |120 |PgXtDvjeJQgc6FzN98KueShvEMa2|viniciusmgaspar@gmail.com|viniciusmgaspar|\n",
      "|1602124737116|14.432000160217285|R. Tôrres Homem, 545 - Vila Isabel, Rio de Janeiro - RJ, 20551-070, Brasil|19.200000762939453|Brasil |-22.9143736|-43.2479302|fused   |7   |3  |23   |9    |116000000|57     |1602124737116|180           |120 |PgXtDvjeJQgc6FzN98KueShvEMa2|viniciusmgaspar@gmail.com|viniciusmgaspar|\n",
      "+-------------+------------------+--------------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+-------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emails: String = viniciusmgaspar@gmail.com\n",
       "joinExpression: org.apache.spark.sql.Column = (uid = uid)\n",
       "joinType: String = inner\n",
       "consultaFinal: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [timestamp_id: string, accuracy: double ... 18 more fields]\n",
       "flatLocationsWithDistDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 19 more fields]\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val emails = \"viniciusmgaspar@gmail.com\"\n",
    "\n",
    "val joinExpression = flatLocationsDF.col(\"uid\") === flatUsersDF.col(\"uid\")\n",
    "var joinType = \"inner\"\n",
    "val consultaFinal = flatLocationsDF.join(flatUsersDF, joinExpression, joinType).drop(flatUsersDF.col(\"uid\")).filter($\"Email\" === emails).orderBy($\"timestamp_id\")\n",
    "\n",
    "consultaFinal.show(5,false)\n",
    "\n",
    "val flatLocationsWithDistDF = consultaFinal.withColumn(\"distance\", when(calculate_distance_col(lat1, lon1, lat2, lon2).isNotNull,calculate_distance_col(lat1, lon1, lat2, lon2)).otherwise(0.0))\n",
    "\n",
    "//val flatLocationsWithDistDF = consultaFinal.withColumn(\"distance\", calculate_distance_col(lat1, lon1, lat2, lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp_id: string (nullable = false)\n",
      " |-- accuracy: double (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- altitude: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- hours: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- nanos: long (nullable = true)\n",
      " |-- seconds: long (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- timezoneOffset: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show walked distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+-----------+-----------+------------------+\n",
      "|username       |data                   |latitude   |longitude  |distance          |\n",
      "+---------------+-----------------------+-----------+-----------+------------------+\n",
      "|viniciusmgaspar|2020-10-07 23:32:51.945|-22.9143424|-43.2479267|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:34:51.961|-22.9143476|-43.2479225|0.720675492840136 |\n",
      "|viniciusmgaspar|2020-10-07 23:36:56.689|-22.9143736|-43.2479302|2.9967018357873862|\n",
      "|viniciusmgaspar|2020-10-07 23:37:57.042|-22.9143736|-43.2479302|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:38:57.116|-22.9143736|-43.2479302|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:40:02.011|-22.914351 |-43.247925 |2.5688213633650445|\n",
      "|viniciusmgaspar|2020-10-07 23:41:02.089|-22.914351 |-43.247925 |0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:42:09.072|-22.9143672|-43.2479284|1.8347079899956038|\n",
      "|viniciusmgaspar|2020-10-07 23:43:09.149|-22.9143672|-43.2479284|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:44:10.298|-22.9143608|-43.2479235|0.8708071547226146|\n",
      "|viniciusmgaspar|2020-10-07 23:45:10.37 |-22.9143608|-43.2479235|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:46:20.77 |-22.9143608|-43.2479235|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:47:20.86 |-22.9143608|-43.2479235|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:48:26.977|-22.9143612|-43.2479639|4.138018973396575 |\n",
      "|viniciusmgaspar|2020-10-07 23:49:33.323|-22.914376 |-43.2479024|6.510281292123442 |\n",
      "|viniciusmgaspar|2020-10-07 23:50:33.676|-22.914376 |-43.2479024|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:51:33.654|-22.9143854|-43.2478801|2.5117802113336802|\n",
      "|viniciusmgaspar|2020-10-07 23:52:33.892|-22.9143854|-43.2478801|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:53:33.964|-22.9143854|-43.2478801|0.0               |\n",
      "|viniciusmgaspar|2020-10-07 23:54:34.786|-22.9143797|-43.2478934|1.5024238063887392|\n",
      "+---------------+-----------------------+-----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF.withColumn(\"data\", (col(\"timestamp_id\")/1000).cast(TimestampType)).orderBy($\"data\".asc)\n",
    ".select(\"username\",\"data\",\"latitude\",\"longitude\",\"distance\")\n",
    "    .show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------+------------------+\n",
      "|email                    |data      |sum(distance)     |\n",
      "+-------------------------+----------+------------------+\n",
      "|viniciusmgaspar@gmail.com|07-10-2020|27.519468577232463|\n",
      "|viniciusmgaspar@gmail.com|08-10-2020|27236.486130992485|\n",
      "|viniciusmgaspar@gmail.com|09-10-2020|9797.745650086401 |\n",
      "+-------------------------+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loc: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [timestamp_id: string, accuracy: double ... 20 more fields]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// flatLocationsWithDistDF.withColumn(\"data\", date_format((col(\"timestamp_id\")/1000).cast(TimestampType),\"dd-MM-yyyy\")).filter($\"data\" >= \"08-10-2020\").show(50)\n",
    "\n",
    "// flatLocationsWithDistDF.withColumn(\"data\", date_format((col(\"timestamp_id\")/1000).cast(TimestampType),\"dd-MM-yyyy\")).filter($\"data\" >= \"08-10-2020\").filter($\"data\" <= \"11-10-2020\").orderBy($\"data\".desc).show(false)\n",
    "\n",
    "\n",
    "//DISTANCIA\n",
    "val loc =  flatLocationsWithDistDF.withColumn(\"data\", (col(\"timestamp_id\")/1000).cast(TimestampType)).orderBy($\"data\".desc)\n",
    "\n",
    "loc.groupBy($\"email\",date_format(col(\"data\"),\"dd-MM-yyyy\").as(\"data\")).sum(\"distance\").orderBy($\"email\".asc, $\"data\".asc)\n",
    ".show(false)\n",
    "    \n",
    "\n",
    "// loc.select($\"email\",$\"data\",$\"distance\").filter($\"distance\" >= 1000).show(500,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------------------+---------------+------------------+----------+\n",
      "| timestamp_id|          accuracy|             address|          altitude|country|   latitude|  longitude|provider|date|day|hours|month|    nanos|seconds|         time|timezoneOffset|year|                 uid|               email|       username|          distance|      data|\n",
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------------------+---------------+------------------+----------+\n",
      "|1602124371945|14.199000358581543|R. Tôrres Homem, ...|19.200000762939453| Brasil|-22.9143424|-43.2479267|   fused|   7|  3|   23|    9|945000000|     51|1602124371945|           180| 120|PgXtDvjeJQgc6FzN9...|viniciusmgaspar@g...|viniciusmgaspar|               0.0|07-10-2020|\n",
      "|1602124491961|13.723999977111816|R. Tôrres Homem, ...|              17.0| Brasil|-22.9143476|-43.2479225|   fused|   7|  3|   23|    9|961000000|     51|1602124491961|           180| 120|PgXtDvjeJQgc6FzN9...|viniciusmgaspar@g...|viniciusmgaspar| 0.720675492840136|07-10-2020|\n",
      "|1602124616689|14.432000160217285|R. Tôrres Homem, ...|19.200000762939453| Brasil|-22.9143736|-43.2479302|   fused|   7|  3|   23|    9|689000000|     56|1602124616689|           180| 120|PgXtDvjeJQgc6FzN9...|viniciusmgaspar@g...|viniciusmgaspar|2.9967018357873862|07-10-2020|\n",
      "|1602124677042|14.432000160217285|R. Tôrres Homem, ...|19.200000762939453| Brasil|-22.9143736|-43.2479302|   fused|   7|  3|   23|    9| 42000000|     57|1602124677042|           180| 120|PgXtDvjeJQgc6FzN9...|viniciusmgaspar@g...|viniciusmgaspar|               0.0|07-10-2020|\n",
      "|1602124737116|14.432000160217285|R. Tôrres Homem, ...|19.200000762939453| Brasil|-22.9143736|-43.2479302|   fused|   7|  3|   23|    9|116000000|     57|1602124737116|           180| 120|PgXtDvjeJQgc6FzN9...|viniciusmgaspar@g...|viniciusmgaspar|               0.0|07-10-2020|\n",
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------------------+---------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF.withColumn(\"data\", date_format((col(\"timestamp_id\")/1000).cast(TimestampType),\"dd-MM-yyyy\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+------------------+\n",
      "| timestamp_id|          accuracy|             address|          altitude|country|   latitude|  longitude|provider|date|day|hours|month|    nanos|seconds|         time|timezoneOffset|year|                 uid|          distance|\n",
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+------------------+\n",
      "|1602281418819|15.708999633789062|R. Tôrres Homem, ...|              28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|819000000|     18|1602281418819|           180| 120|PgXtDvjeJQgc6FzN9...|  5322025.72753382|\n",
      "|1602281495309|15.708999633789062|R. Tôrres Homem, ...|              28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|309000000|     35|1602281495309|           180| 120|PgXtDvjeJQgc6FzN9...|               0.0|\n",
      "|1602281539780|15.708999633789062|R. Tôrres Homem, ...|              28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|780000000|     19|1602281539780|           180| 120|PgXtDvjeJQgc6FzN9...|               0.0|\n",
      "|1602281658266|15.708999633789062|R. Tôrres Homem, ...|              28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|266000000|     18|1602281658266|           180| 120|PgXtDvjeJQgc6FzN9...|               0.0|\n",
      "|1602148956000|              16.0|R. Srg. Aquino, 2...| 2.700000047683716| Brasil|-22.8380618|-43.2618868|   fused|   8|  4|    6|    9|        0|     36|1602148956000|           180| 120|uF9x6cGOL9bclGCkk...| 5320111.557192228|\n",
      "|1602166175245| 16.06999969482422|R. Saint Roman, 1...|              10.0| Brasil|-22.9807524|-43.1919608|   fused|   8|  4|   11|    9|245000000|     35|1602166175245|           180| 120|5Jf44SGWhzZmxsZs7...| 5319565.469214094|\n",
      "|1602165991037|29.041000366210938|R. Saint Roman, 1...| 9.600000381469727| Brasil|-22.9807428|-43.1919671|   fused|   8|  4|   11|    9| 37000000|     31|1602165991037|           180| 120|5Jf44SGWhzZmxsZs7...| 5319565.654802892|\n",
      "|1602166113027|29.041000366210938|R. Saint Roman, 1...| 9.600000381469727| Brasil|-22.9807428|-43.1919671|   fused|   8|  4|   11|    9| 27000000|     33|1602166113027|           180| 120|5Jf44SGWhzZmxsZs7...|               0.0|\n",
      "|1602341142695|111.31500244140625|Rua Dona Mariana,...|              16.5| Brazil|-22.9556239|-43.1876238|   fused|  10|  6|   11|    9|695000000|     42|1602341142695|           180| 120|H5LG3vN3jcPlcbJ2A...| 5318082.931387919|\n",
      "|1602195567256|18.231000900268555|R. Tôrres Homem, ...|              17.0| Brasil|-22.9144218|-43.2477969|   fused|   8|  4|   19|    9|256000000|     27|1602195567256|           180| 120|PgXtDvjeJQgc6FzN9...| 5322019.796916806|\n",
      "|1602286254702|18.256000518798828|R. Tôrres Homem, ...|19.899999618530273| Brasil|-22.9144218|-43.2478089|   fused|   9|  5|   20|    9|702000000|     54|1602286254702|           180| 120|PgXtDvjeJQgc6FzN9...| 4412722.326216662|\n",
      "|1602178745581| 13.98799991607666|R. Srg. Aquino, 2...| 2.700000047683716| Brasil|-22.8381272|-43.2623402|   fused|   8|  4|   14|    9|581000000|      5|1602178745581|           180| 120|uF9x6cGOL9bclGCkk...| 5320157.283664884|\n",
      "|1602178850443| 108.5479965209961|R. Srg. Aquino, 2...| 2.700000047683716| Brasil|-22.8381272|-43.2623402|   fused|   8|  4|   14|    9|443000000|     50|1602178850443|           180| 120|uF9x6cGOL9bclGCkk...|               0.0|\n",
      "|1602168423000| 6.730000019073486|R. Sá Ferreira, 7...| 6.599999904632568| Brasil|-22.9808752|-43.1919171|   fused|   8|  4|   11|    9|        0|      3|1602168423000|           180| 120|5Jf44SGWhzZmxsZs7...|   5319566.5819256|\n",
      "|1602182125609|17.607999801635742|Rua Humaitá, 298 ...| 12.40000057220459| Brasil|-22.9599858|-43.2024837|   fused|   8|  4|   15|    9|609000000|     25|1602182125609|           180| 120|PgXtDvjeJQgc6FzN9...|5319674.0524577405|\n",
      "|1602127248371| 11.59000015258789|R. Mena Barreto, ...|15.300000190734863| Brazil|-22.9556648|-43.1880704|   fused|   8|  4|    0|    9|371000000|     48|1602127248371|           180| 120|H5LG3vN3jcPlcbJ2A...| 5318126.903319926|\n",
      "|1602216350578|17.489999771118164|Rua Dona Mariana,...| 12.40000057220459| Brazil|-22.9556648|-43.1880072|   fused|   9|  5|    1|    9|578000000|     50|1602216350578|           180| 120|H5LG3vN3jcPlcbJ2A...|  4405270.82255842|\n",
      "|1602216410122|17.489999771118164|Rua Dona Mariana,...| 12.40000057220459| Brazil|-22.9556648|-43.1880072|   fused|   9|  5|    1|    9|122000000|     50|1602216410122|           180| 120|H5LG3vN3jcPlcbJ2A...|               0.0|\n",
      "|1602216441162|12.760000228881836|R. Mena Barreto, ...| 7.400000095367432| Brazil|-22.9556648|-43.1880761|   fused|   9|  5|    1|    9|162000000|     21|1602216441162|           180| 120|H5LG3vN3jcPlcbJ2A...| 4405277.794579262|\n",
      "|1602164887567|22.625999450683594|R. Tôrres Homem, ...| 27.80000114440918| Brasil|-22.9143416|-43.2479164|   fused|   8|  4|   10|    9|567000000|      7|1602164887567|           180| 120|PgXtDvjeJQgc6FzN9...| 5322027.694930456|\n",
      "+-------------+------------------+--------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sqlDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 17 more fields]\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Register the DataFrame as a SQL temporary view\n",
    "flatLocationsWithDistDF.createOrReplaceTempView(\"flatLocationSQL\")\n",
    "\n",
    "val sqlDF = spark.sql(\"SELECT * FROM flatLocationSQL\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of reduceByKey to sum up values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://cln-rio-06:4041\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1602515908080)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "<console>",
     "evalue": "24: error: not found: value flatLocationsWithDistDF",
     "output_type": "error",
     "traceback": [
      "<console>:24: error: not found: value flatLocationsWithDistDF",
      "       val userReducedDistance = flatLocationsWithDistDF.reduceByKey((v1,v2) => v1 + v2)",
      "                                 ^",
      ""
     ]
    }
   ],
   "source": [
    "val userReducedDistance = flatLocationsWithDistDF.reduceByKey((v1,v2) => v1 + v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
