{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data - Final Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configuration for Spark + JVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.master = \"local[*]\"\n",
    "launcher.driver_memory = '20g'\n",
    "launcher.executor_memory = '20g'\n",
    "launcher.verbose = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.conf.set(\"spark.app.name\", \"scalaXgbTest\")\n",
    "launcher.num_executors = 3\n",
    "launcher.executor_cores = 7 //launcher.conf.spark.executor.cores = 8\n",
    "launcher.conf.spark.task.cpus = 6\n",
    "launcher.driver_memory = '4g'\n",
    "launcher.executor_memory = '4g'\n",
    "launcher.conf.set(\"spark.executor.heartbeatInterval\", \"6000s\")\n",
    "launcher.conf.set(\"spark.yarn.scheduler.heartbeat.interval-ms\", \"10000s\")\n",
    "launcher.conf.set(\"spark.network.timeout\", \"10000s\")\n",
    "launcher.conf.set(\"spark.yarn.executor.memoryOverhead\", \"8192\")\n",
    "launcher.conf.set(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "launcher.jars = [\"file://some/jar.jar\", \"xgboost-maven-0.82/xgboost4j-spark-0.82.jar\", \"xgboost-maven-0.82/xgboost4j-0.82.jar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spylon-kernel\n",
      "local[*]\n"
     ]
    }
   ],
   "source": [
    "println(sc.appName)\n",
    "println(sc.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n",
       "import org.apache.spark.sql.expressions._\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._      // include the Spark Types to define our schema\n",
    "import org.apache.spark.sql.functions._  // include the Spark helper functions\n",
    "import spark.implicits._                 // For implicit conversions like converting RDDs to DataFrames\n",
    "import org.apache.spark.sql.expressions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_schema: org.apache.spark.sql.types.MapType = MapType(StringType,StructType(StructField(accuracy,DoubleType,true), StructField(address,StringType,true), StructField(altitude,DoubleType,true), StructField(country,StringType,true), StructField(latitude,DoubleType,true), StructField(longitude,DoubleType,true), StructField(provider,StringType,true), StructField(timestamp,StructType(StructField(date,LongType,true), StructField(day,LongType,true), StructField(hours,LongType,true), StructField(month,LongType,true), StructField(nanos,LongType,true), StructField(seconds,LongType,true), StructField(time,LongType,true), StructField(timezoneOffset,LongType,true), StructField(year,LongType,true)),true), StructField(uid,StringType,true)),true)\n",
       "schema: org.apache.spark.sql.types.StructType = S...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val location_schema =\n",
    "    MapType(StringType,\n",
    "        new StructType()\n",
    "            .add(\"accuracy\", DoubleType)\n",
    "            .add(\"address\", StringType)\n",
    "            .add(\"altitude\", DoubleType)\n",
    "            .add(\"country\", StringType)\n",
    "            .add(\"latitude\", DoubleType)\n",
    "            .add(\"longitude\", DoubleType)\n",
    "            .add(\"provider\", StringType)\n",
    "            .add(\"timestamp\", \n",
    "             new StructType()\n",
    "                .add(\"date\", LongType)\n",
    "                .add(\"day\", LongType)\n",
    "                .add(\"hours\", LongType)\n",
    "                .add(\"month\", LongType)\n",
    "                .add(\"nanos\", LongType)\n",
    "                .add(\"seconds\", LongType)\n",
    "                .add(\"time\", LongType)\n",
    "                .add(\"timezoneOffset\", LongType)\n",
    "                .add(\"year\", LongType)\n",
    "            )\n",
    "            .add(\"uid\", StringType)\n",
    "        )\n",
    "\n",
    "val schema = new StructType()\n",
    "    .add(\"locations\", location_schema)\n",
    "    .add(\"user-locations\",\n",
    "        MapType(StringType, location_schema)\n",
    "    )\n",
    "    .add(\"users\",\n",
    "        MapType(StringType,\n",
    "            new StructType()\n",
    "                .add(\"email\", StringType)\n",
    "                .add(\"username\", StringType)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [locations: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>, user-locations: map<string,map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>> ... 1 more field]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"multiline\", true).schema(schema).json(\"trackme-sample-data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- locations: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- accuracy: double (nullable = true)\n",
      " |    |    |-- address: string (nullable = true)\n",
      " |    |    |-- altitude: double (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- latitude: double (nullable = true)\n",
      " |    |    |-- longitude: double (nullable = true)\n",
      " |    |    |-- provider: string (nullable = true)\n",
      " |    |    |-- timestamp: struct (nullable = true)\n",
      " |    |    |    |-- date: long (nullable = true)\n",
      " |    |    |    |-- day: long (nullable = true)\n",
      " |    |    |    |-- hours: long (nullable = true)\n",
      " |    |    |    |-- month: long (nullable = true)\n",
      " |    |    |    |-- nanos: long (nullable = true)\n",
      " |    |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |    |-- time: long (nullable = true)\n",
      " |    |    |    |-- timezoneOffset: long (nullable = true)\n",
      " |    |    |    |-- year: long (nullable = true)\n",
      " |    |    |-- uid: string (nullable = true)\n",
      " |-- user-locations: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: map (valueContainsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |    |-- accuracy: double (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |    |-- altitude: double (nullable = true)\n",
      " |    |    |    |-- country: string (nullable = true)\n",
      " |    |    |    |-- latitude: double (nullable = true)\n",
      " |    |    |    |-- longitude: double (nullable = true)\n",
      " |    |    |    |-- provider: string (nullable = true)\n",
      " |    |    |    |-- timestamp: struct (nullable = true)\n",
      " |    |    |    |    |-- date: long (nullable = true)\n",
      " |    |    |    |    |-- day: long (nullable = true)\n",
      " |    |    |    |    |-- hours: long (nullable = true)\n",
      " |    |    |    |    |-- month: long (nullable = true)\n",
      " |    |    |    |    |-- nanos: long (nullable = true)\n",
      " |    |    |    |    |-- seconds: long (nullable = true)\n",
      " |    |    |    |    |-- time: long (nullable = true)\n",
      " |    |    |    |    |-- timezoneOffset: long (nullable = true)\n",
      " |    |    |    |    |-- year: long (nullable = true)\n",
      " |    |    |    |-- uid: string (nullable = true)\n",
      " |-- users: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: struct (valueContainsNull = true)\n",
      " |    |    |-- email: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "locationsDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, value: struct<accuracy: double, address: string ... 7 more fields>]\n",
       "userLocationsDF: org.apache.spark.sql.DataFrame = [uid: string, timestamp: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>]\n",
       "usersDF: org.apache.spark.sql.DataFrame = [uid: string, user_attr: struct<email: string, username: string>]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val locationsDF = df.select(explode($\"locations\") as Seq(\"timestamp_id\", \"value\"))\n",
    "val userLocationsDF = df.select(explode($\"user-locations\") as Seq(\"uid\", \"timestamp\"))\n",
    "val usersDF = df.select(explode($\"users\") as Seq(\"uid\", \"user_attr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = false)\n",
      " |-- user_attr: struct (nullable = true)\n",
      " |    |-- email: string (nullable = true)\n",
      " |    |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to flatten schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Column\n",
       "flattenSchema: (schema: org.apache.spark.sql.types.StructType, prefix: String)Array[org.apache.spark.sql.Column]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Column\n",
    "\n",
    "def flattenSchema(schema: StructType, prefix: String = null) : Array[Column] = {\n",
    "  schema.fields.flatMap(f => {\n",
    "    val colName = if (prefix == null) f.name else (prefix + \".\" + f.name)\n",
    "\n",
    "    f.dataType match {\n",
    "      case st: StructType => flattenSchema(st, colName)\n",
    "      case _ => Array(col(colName))\n",
    "    }\n",
    "  })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat struct DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatLocationsDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 16 more fields]\n",
       "flatUserLocationsDF: org.apache.spark.sql.DataFrame = [uid: string, timestamp: map<string,struct<accuracy:double,address:string,altitude:double,country:string,latitude:double,longitude:double,provider:string,timestamp:struct<date:bigint,day:bigint,hours:bigint,month:bigint,nanos:bigint,seconds:bigint,time:bigint,timezoneOffset:bigint,year:bigint>,uid:string>>]\n",
       "flatUsersDF: org.apache.spark.sql.DataFrame = [uid: string, email: string ... 1 more field]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flatLocationsDF = locationsDF.select(flattenSchema(locationsDF.schema):_*)\n",
    "val flatUserLocationsDF = userLocationsDF.select(flattenSchema(userLocationsDF.schema):_*)\n",
    "val flatUsersDF = usersDF.select(flattenSchema(usersDF.schema):_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp_id: string (nullable = false)\n",
      " |-- accuracy: double (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- altitude: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- hours: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- nanos: long (nullable = true)\n",
      " |-- seconds: long (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- timezoneOffset: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+\n",
      "|timestamp_id |accuracy          |address                                                                |altitude          |country|latitude   |longitude  |provider|date|day|hours|month|nanos    |seconds|time         |timezoneOffset|year|uid                         |\n",
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+\n",
      "|1602119776824|15.666000366210938|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|14.90000057220459 |Brazil |-22.9556468|-43.1880249|fused   |7   |3  |22   |9    |824000000|16     |1602119776824|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602119934507|15.967000007629395|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|15.300000190734863|Brazil |-22.9556367|-43.1880211|fused   |7   |3  |22   |9    |507000000|54     |1602119934507|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602120846895|22.099000930786133|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|16.799999237060547|Brazil |-22.9556134|-43.1879997|fused   |7   |3  |22   |9    |895000000|6      |1602120846895|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121213639|15.10200023651123 |R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|14.90000057220459 |Brazil |-22.9556477|-43.1880597|fused   |7   |3  |22   |9    |639000000|13     |1602121213639|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121277958|13.876999855041504|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8381181|-43.2623295|fused   |7   |3  |22   |9    |958000000|17     |1602121277958|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121409097|15.027999877929688|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8381179|-43.2623138|fused   |7   |3  |22   |9    |97000000 |29     |1602121409097|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121530180|14.98799991607666 |R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.838109 |-43.2623071|fused   |7   |3  |22   |9    |180000000|30     |1602121530180|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121655540|13.994999885559082|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.4000000953674316|Brasil |-22.8381141|-43.2623158|fused   |7   |3  |22   |9    |540000000|35     |1602121655540|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121736870|14.697999954223633|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|8.699999809265137 |Brazil |-22.9556593|-43.1880598|fused   |7   |3  |22   |9    |870000000|56     |1602121736870|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121751000|19.0              |R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.837858 |-43.2621474|fused   |7   |3  |22   |9    |0        |11     |1602121751000|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121773593|13.946999549865723|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|8.699999809265137 |Brazil |-22.9556522|-43.1880422|fused   |7   |3  |22   |9    |593000000|33     |1602121773593|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121834763|14.918000221252441|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|8.699999809265137 |Brazil |-22.9556413|-43.1880571|fused   |7   |3  |22   |9    |763000000|34     |1602121834763|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121840113|1100.0            |Av. Brasil, 9200 - Penha, Rio de Janeiro - RJ, 21012-350, Brasil       |27.0              |Brasil |-22.8339884|-43.259253 |fused   |7   |3  |22   |9    |113000000|40     |1602121840113|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121896253|14.197999954223633|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|8.699999809265137 |Brazil |-22.9556438|-43.1880622|fused   |7   |3  |22   |9    |253000000|36     |1602121896253|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121935763|39.430999755859375|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8380786|-43.2621135|fused   |7   |3  |22   |9    |763000000|15     |1602121935763|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602121957435|14.581999778747559|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|14.90000057220459 |Brazil |-22.9555958|-43.1880177|fused   |7   |3  |22   |9    |435000000|37     |1602121957435|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602121987617|12.493000030517578|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8381159|-43.2623215|fused   |7   |3  |22   |9    |617000000|7      |1602121987617|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602122047811|14.772000312805176|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|13.300000190734863|Brazil |-22.9555982|-43.1880122|fused   |7   |3  |22   |9    |811000000|7      |1602122047811|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|\n",
      "|1602122055711|12.493000030517578|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8381159|-43.2623215|fused   |7   |3  |22   |9    |711000000|15     |1602122055711|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "|1602122082028|17.5              |R. Srg. Aquino, 348 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.4000000953674316|Brasil |-22.8381448|-43.2623323|fused   |7   |3  |22   |9    |28000000 |42     |1602122082028|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|\n",
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.math._\n",
       "calculate_distance_elem: (lat1: Double, lon1: Double, lat2: Double, lon2: Double)Double\n",
       "calculate_distance_elem_sqlfunc: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$3429/799971909@1622c15e,DoubleType,List(Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double]), Some(class[value[0]: double])),None,false,true)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.math._\n",
    "\n",
    "def calculate_distance_elem(lat1:Double, lon1:Double, lat2:Double, lon2:Double):Double = {   \n",
    "    val earth_radius = 6371e3;           // meters\n",
    "    val phi1 = lat1 * Pi/180;                  // radians\n",
    "    val phi2 = lat2 * Pi/180;                  // radians\n",
    "    val delta_phi = phi2 - phi1;               // radians\n",
    "\n",
    "    val delta_lampda = (lon2 - lon1) * Pi/180; // radians\n",
    "\n",
    "    val a = sin(delta_phi/2)*sin(delta_phi/2) + cos(phi1)*cos(phi2)*sin(delta_lampda/2)*sin(delta_lampda/2);\n",
    "    val c = 2*atan2(sqrt(a), sqrt(1-a));\n",
    "\n",
    "    val d = earth_radius*c; // meters\n",
    "    \n",
    "    return d\n",
    "}\n",
    "\n",
    "val calculate_distance_elem_sqlfunc = udf(calculate_distance_elem(_,_,_,_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test calculate_distance_elem function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat1: Double = -22.9556473\n",
       "lon1: Double = -43.1881019\n",
       "lat2: Double = -23.9556473\n",
       "lon2: Double = -44.1881019\n",
       "dist: Double = 150894.75616346067\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lat1 = -22.9556473\n",
    "val lon1 = -43.1881019\n",
    "\n",
    "val lat2 = -23.9556473\n",
    "val lon2 = -44.1881019\n",
    "\n",
    "val dist = calculate_distance_elem(lat1, lon1, lat2, lon2)\n",
    "\n",
    "assert (dist == 150894.75616346067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "calculate_distance_col: (lat1: org.apache.spark.sql.Column, lon1: org.apache.spark.sql.Column, lat2: org.apache.spark.sql.Column, lon2: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//import scala.math._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "def calculate_distance_col(lat1:org.apache.spark.sql.Column, lon1:org.apache.spark.sql.Column, lat2:org.apache.spark.sql.Column, lon2:org.apache.spark.sql.Column):org.apache.spark.sql.Column = {   \n",
    "    val earth_radius = 6371e3;           // meters\n",
    "    val pi_over_180 = lit(Pi/180);\n",
    "    val phi1 = lat1 * pi_over_180;                  // radians\n",
    "    val phi2 = lat2 * pi_over_180;                  // radians\n",
    "    val delta_phi = phi2 - phi1;               // radians\n",
    "\n",
    "    val delta_lampda = (lon2 - lon1) * pi_over_180; // radians\n",
    "\n",
    "    val a = sin(delta_phi/2)*sin(delta_phi/2) + cos(phi1)*cos(phi2)*sin(delta_lampda/2)*sin(delta_lampda/2);\n",
    "    val c = lit(2)*atan2(sqrt(a), sqrt(lit(1)-a));\n",
    "\n",
    "    val d = lit(earth_radius)*c; // meters\n",
    "    \n",
    "    return d;\n",
    "}\n",
    "\n",
    "// val calculate_distance_sqlfunc = udf(calculate_distance(_,_,_,_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat_col: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@6c539996\n",
       "lon_col: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@57ef6b85\n",
       "lat2: org.apache.spark.sql.Column = latitude\n",
       "lat1: org.apache.spark.sql.Column = lag(latitude, 1, NULL) OVER (PARTITION BY latitude ORDER BY timestamp_id ASC NULLS FIRST unspecifiedframe$())\n",
       "lon2: org.apache.spark.sql.Column = longitude\n",
       "lon1: org.apache.spark.sql.Column = lag(longitude, 1, NULL) OVER (PARTITION BY longitude ORDER BY timestamp_id ASC NULLS FIRST unspecifiedframe$())\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lat_col = Window.partitionBy(\"latitude\").orderBy($\"timestamp_id\".asc)\n",
    "val lon_col = Window.partitionBy(\"longitude\").orderBy($\"timestamp_id\".asc)\n",
    "\n",
    "val lat2 = col(\"latitude\")\n",
    "// val lat1 = lag(\"latitude\", 1).over(lat_col)\n",
    "val lat1 = when((lag(\"latitude\", 1).over(lat_col)).isNotNull, lag(\"latitude\", 1).over(lat_col)).otherwise($\"latitude\")\n",
    "\n",
    "val lon2 = col(\"longitude\")\n",
    "// val lon1 = lag(\"longitude\", 1).over(lat_col)\n",
    "val lon1 = when((lag(\"longitude\", 1).over(lon_col)).isNotNull, lag(\"longitude\", 1).over(lon_col)).otherwise($\"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatLocationsWithDistDF: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 17 more fields]\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flatLocationsWithDistDF = flatLocationsDF.withColumn(\"distance\", calculate_distance_col(lat1, lon1, lat2, lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp_id: string (nullable = false)\n",
      " |-- accuracy: double (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- altitude: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- hours: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- nanos: long (nullable = true)\n",
      " |-- seconds: long (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- timezoneOffset: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|distance|\n",
      "+--------+\n",
      "|    null|\n",
      "|     0.0|\n",
      "|     0.0|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|     0.0|\n",
      "|    null|\n",
      "|     0.0|\n",
      "+--------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF\n",
    ".select(\"distance\")\n",
    "    .show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+---------------------------+-----------------+\n",
      "|timestamp_id |accuracy          |address                                                                |altitude          |country|latitude   |longitude  |provider|date|day|hours|month|nanos    |seconds|time         |timezoneOffset|year|uid                         |email                      |username         |\n",
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+---------------------------+-----------------+\n",
      "|1602119776824|15.666000366210938|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|14.90000057220459 |Brazil |-22.9556468|-43.1880249|fused   |7   |3  |22   |9    |824000000|16     |1602119776824|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|henrique.mageste@gmail.com |henrique.mageste |\n",
      "|1602119934507|15.967000007629395|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|15.300000190734863|Brazil |-22.9556367|-43.1880211|fused   |7   |3  |22   |9    |507000000|54     |1602119934507|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|henrique.mageste@gmail.com |henrique.mageste |\n",
      "|1602120846895|22.099000930786133|R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|16.799999237060547|Brazil |-22.9556134|-43.1879997|fused   |7   |3  |22   |9    |895000000|6      |1602120846895|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|henrique.mageste@gmail.com |henrique.mageste |\n",
      "|1602121213639|15.10200023651123 |R. Mena Barreto, 182 - Botafogo, Rio de Janeiro - RJ, 22271-100, Brazil|14.90000057220459 |Brazil |-22.9556477|-43.1880597|fused   |7   |3  |22   |9    |639000000|13     |1602121213639|180           |120 |H5LG3vN3jcPlcbJ2A5RGo6H4AHw2|henrique.mageste@gmail.com |henrique.mageste |\n",
      "|1602121277958|13.876999855041504|R. Srg. Aquino, 276 - Olaria, Rio de Janeiro - RJ, 21021-640, Brasil   |2.700000047683716 |Brasil |-22.8381181|-43.2623295|fused   |7   |3  |22   |9    |958000000|17     |1602121277958|180           |120 |uF9x6cGOL9bclGCkkV2PkrcwnIz1|wallace.mendes.rj@gmail.com|wallace.mendes.rj|\n",
      "+-------------+------------------+-----------------------------------------------------------------------+------------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+----------------------------+---------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emails: String = wallace.mendes.rj@gmail.com\n",
       "joinExpression: org.apache.spark.sql.Column = (uid = uid)\n",
       "joinType: String = inner\n",
       "consultaFinal: org.apache.spark.sql.DataFrame = [timestamp_id: string, accuracy: double ... 18 more fields]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val emails = \"wallace.mendes.rj@gmail.com\"\n",
    "\n",
    "val joinExpression = flatLocationsDF.col(\"uid\") === flatUsersDF.col(\"uid\")\n",
    "var joinType = \"inner\"\n",
    "val consultaFinal = flatLocationsDF.join(flatUsersDF, joinExpression, joinType).drop(flatUsersDF.col(\"uid\"))//.filter($\"Email\" === emails)\n",
    "\n",
    "consultaFinal.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+--------------------+-----------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------+---------+\n",
      "| timestamp_id|          accuracy|             address|         altitude|country|   latitude|  longitude|provider|date|day|hours|month|    nanos|seconds|         time|timezoneOffset|year|                 uid|distance|     data|\n",
      "+-------------+------------------+--------------------+-----------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------+---------+\n",
      "|1602281418819|15.708999633789062|R. T么rres Homem, ...|             28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|819000000|     18|1602281418819|           180| 120|PgXtDvjeJQgc6FzN9...|    null|5/10/2020|\n",
      "|1602281495309|15.708999633789062|R. T么rres Homem, ...|             28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|309000000|     35|1602281495309|           180| 120|PgXtDvjeJQgc6FzN9...|     0.0|5/10/2020|\n",
      "|1602281539780|15.708999633789062|R. T么rres Homem, ...|             28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|780000000|     19|1602281539780|           180| 120|PgXtDvjeJQgc6FzN9...|     0.0|5/10/2020|\n",
      "|1602281658266|15.708999633789062|R. T么rres Homem, ...|             28.0| Brasil|-22.9143819|-43.2478775|   fused|   9|  5|   19|    9|266000000|     18|1602281658266|           180| 120|PgXtDvjeJQgc6FzN9...|     0.0|5/10/2020|\n",
      "|1602148956000|              16.0|R. Srg. Aquino, 2...|2.700000047683716| Brasil|-22.8380618|-43.2618868|   fused|   8|  4|    6|    9|        0|     36|1602148956000|           180| 120|uF9x6cGOL9bclGCkk...|    null|4/10/2020|\n",
      "+-------------+------------------+--------------------+-----------------+-------+-----------+-----------+--------+----+---+-----+-----+---------+-------+-------------+--------------+----+--------------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flatLocationsWithDistDF.withColumn(\"data\", concat($\"day\",lit(\"/\"),$\"month\"+1,lit(\"/\"),$\"year\"+1900)).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
